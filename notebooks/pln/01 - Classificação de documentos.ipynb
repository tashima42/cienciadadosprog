{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ae7603",
   "metadata": {},
   "source": [
    "# Classificação de Documentos\n",
    "\n",
    "Numa tarefa de classificação, usamos um algoritmo capaz de aprender, a partir de alguns exemplos, como classificar novos elementos. No caso de texto, precisamos oferecer alguns documentos já classificados. No exemplo abaixo usamos notícias do corpus Fake.br já classificadas como verdadeiras ou falsas. O algoritmo usado é o Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c32dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c42da",
   "metadata": {},
   "source": [
    "## Lendo as notícias dos arquivos\n",
    "Neste exemplo vamos usar uma amostra do corpus Fake.br (https://github.com/roneysco/Fake.br-Corpus). Precisamos selecionar o diretório contendo os documentos. Neste diretório existem dois outros diretórios, o \"fake\", no qual estão os arquivos de notícias falsas, e o \"true\", no qual estão as notícias verdadeiras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed319e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos = []\n",
    "\n",
    "# Lê documentos dos diretórios e monta o dataframe\n",
    "for category in os.listdir('fake-br-corpus-sample'):\n",
    "    for doc in os.listdir(f'fake-br-corpus-sample/{category}'):\n",
    "        name = doc.split('.')[0]\n",
    "        path = f'fake-br-corpus-sample/{category}/{doc}'\n",
    "        content = open(path, \"r\", encoding=\"utf-8\").read()\n",
    "        documento = {\"CATEGORY\" : category, \"NAME\": name, \"PATH\": path, \"CONTENT\": content}\n",
    "        documentos.append(documento)\n",
    "\n",
    "df = pd.DataFrame(documentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617675e",
   "metadata": {},
   "source": [
    "## Visualização dos dados\n",
    "Pode-se visualizar, utilizando o DataFrame criado, as notícias e campos de dados associados a elas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568293d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>NAME</th>\n",
       "      <th>PATH</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>14</td>\n",
       "      <td>fake-br-corpus-sample/true/14.txt</td>\n",
       "      <td>Raquel Dodge reitera pedido de Janot para resc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>3</td>\n",
       "      <td>fake-br-corpus-sample/true/3.txt</td>\n",
       "      <td>﻿Após o prefeito de Manaus Arthur Virgílio (PS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true</td>\n",
       "      <td>15</td>\n",
       "      <td>fake-br-corpus-sample/true/15.txt</td>\n",
       "      <td>Anthony Garotinho deixa Bangu com festa de ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true</td>\n",
       "      <td>2</td>\n",
       "      <td>fake-br-corpus-sample/true/2.txt</td>\n",
       "      <td>Em evento realizado nesta terça-feira para div...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>16</td>\n",
       "      <td>fake-br-corpus-sample/true/16.txt</td>\n",
       "      <td>Conselho de Ética do PMDB decide expulsar a se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>true</td>\n",
       "      <td>8</td>\n",
       "      <td>fake-br-corpus-sample/true/8.txt</td>\n",
       "      <td>Cuba comemorará o primeiro aniversário da mort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>true</td>\n",
       "      <td>18</td>\n",
       "      <td>fake-br-corpus-sample/true/18.txt</td>\n",
       "      <td>Fachin nega novo pedido de liberdade de Joesle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>true</td>\n",
       "      <td>13</td>\n",
       "      <td>fake-br-corpus-sample/true/13.txt</td>\n",
       "      <td>Gilmar nega pedido de Miller para se declarar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>true</td>\n",
       "      <td>20</td>\n",
       "      <td>fake-br-corpus-sample/true/20.txt</td>\n",
       "      <td>PMDB aprova mudança de nome e passa a ser cham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>true</td>\n",
       "      <td>9</td>\n",
       "      <td>fake-br-corpus-sample/true/9.txt</td>\n",
       "      <td>s doleiros acusados de lavar dinheiro roubado ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY NAME                               PATH  \\\n",
       "0     true   14  fake-br-corpus-sample/true/14.txt   \n",
       "1     true    3   fake-br-corpus-sample/true/3.txt   \n",
       "2     true   15  fake-br-corpus-sample/true/15.txt   \n",
       "3     true    2   fake-br-corpus-sample/true/2.txt   \n",
       "4     true   16  fake-br-corpus-sample/true/16.txt   \n",
       "5     true    8   fake-br-corpus-sample/true/8.txt   \n",
       "6     true   18  fake-br-corpus-sample/true/18.txt   \n",
       "7     true   13  fake-br-corpus-sample/true/13.txt   \n",
       "8     true   20  fake-br-corpus-sample/true/20.txt   \n",
       "9     true    9   fake-br-corpus-sample/true/9.txt   \n",
       "\n",
       "                                             CONTENT  \n",
       "0  Raquel Dodge reitera pedido de Janot para resc...  \n",
       "1  ﻿Após o prefeito de Manaus Arthur Virgílio (PS...  \n",
       "2  Anthony Garotinho deixa Bangu com festa de ali...  \n",
       "3  Em evento realizado nesta terça-feira para div...  \n",
       "4  Conselho de Ética do PMDB decide expulsar a se...  \n",
       "5  Cuba comemorará o primeiro aniversário da mort...  \n",
       "6  Fachin nega novo pedido de liberdade de Joesle...  \n",
       "7  Gilmar nega pedido de Miller para se declarar ...  \n",
       "8  PMDB aprova mudança de nome e passa a ser cham...  \n",
       "9  s doleiros acusados de lavar dinheiro roubado ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85967ef",
   "metadata": {},
   "source": [
    "## Preprocessamento do texto das notícias\n",
    "Nas análises a seguir, vamos focar na coluna CONTENT, que é a que contém o texto das notícias no dataset. Primeiramente, obtemos as stopwords definidas para o portugês no NLTK. Stopwords são palavras que são muito comuns e por conta disso podem atrapalhar as análises. Nos próximos passos vamos remover estas palavras dos textos.\n",
    "A função remove_acentos definida abaixo converte caracteres acentuados em caracteres comuns. Vamos utilizá-la para remover estes caracteres especiais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "073a8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomente e execute os comandos abaixo se for o primeiro uso dos recursos do NLTK\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b74708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    raquel dodge reitera pedido janot rescindir de...\n",
      "1    prefeito manaus arthur virgilio psdb ter envia...\n",
      "2    anthony garotinho deixa bangu festa aliados at...\n",
      "3    evento realizado nesta divulgar jogo estrelas ...\n",
      "4    conselho etica pmdb decide expulsar senadora k...\n",
      "Name: CONTENT_NORMALIZADO, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import unicodedata\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "def remove_acentos(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "stopwords = [remove_acentos(palavra) for palavra in stopwords]\n",
    "\n",
    "def normaliza_texto(txt):\n",
    "    return ' '.join([word for word in word_tokenize(str.lower(remove_acentos(txt))) if word not in stopwords and word.isalpha()])\n",
    "\n",
    "df['CONTENT_NORMALIZADO'] = df.apply(lambda linha: normaliza_texto(str(linha['CONTENT'])), axis = 1)\n",
    "\n",
    "print(df['CONTENT_NORMALIZADO'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073612d2",
   "metadata": {},
   "source": [
    "## Amostragem de dados para treinamento\n",
    "Para separar os nossos documentos entre dados de treinamento e dados que vamos usar posteriormente para avaliação, usamos um método de amostragem de dados da biblioteca Sklearn. Selecionamos 70% dos documentos para usarmos no treinamento classificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943581af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>NAME</th>\n",
       "      <th>PATH</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CONTENT_NORMALIZADO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>true</td>\n",
       "      <td>11</td>\n",
       "      <td>fake-br-corpus-sample/true/11.txt</td>\n",
       "      <td>Anthony Garotinho é ouvido mais uma vez sobre ...</td>\n",
       "      <td>anthony garotinho ouvido vez sobre suposta agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>true</td>\n",
       "      <td>17</td>\n",
       "      <td>fake-br-corpus-sample/true/17.txt</td>\n",
       "      <td>﻿Juiz determina soltura de 4 presos por pensão...</td>\n",
       "      <td>determina soltura presos pensao alimenticia co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>true</td>\n",
       "      <td>10</td>\n",
       "      <td>fake-br-corpus-sample/true/10.txt</td>\n",
       "      <td>Bolsonaro é um liberal completo, diz president...</td>\n",
       "      <td>bolsonaro liberal completo diz presidente psl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fake</td>\n",
       "      <td>18</td>\n",
       "      <td>fake-br-corpus-sample/fake/18.txt</td>\n",
       "      <td>Joesley chorou ao entrar na cela e está sem co...</td>\n",
       "      <td>joesley chorou entrar cela comer tomar banho d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>16</td>\n",
       "      <td>fake-br-corpus-sample/true/16.txt</td>\n",
       "      <td>Conselho de Ética do PMDB decide expulsar a se...</td>\n",
       "      <td>conselho etica pmdb decide expulsar senadora k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>true</td>\n",
       "      <td>4</td>\n",
       "      <td>fake-br-corpus-sample/true/4.txt</td>\n",
       "      <td>﻿Doria vai receber Zé Celso após reunião com r...</td>\n",
       "      <td>vai receber ze celso apos reuniao representant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>fake</td>\n",
       "      <td>19</td>\n",
       "      <td>fake-br-corpus-sample/fake/19.txt</td>\n",
       "      <td>Nós vamos estuprar os corruptos afirmam pres...</td>\n",
       "      <td>vamos estuprar afirmam presos papuda mensagens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fake</td>\n",
       "      <td>13</td>\n",
       "      <td>fake-br-corpus-sample/fake/13.txt</td>\n",
       "      <td>Gilmar Mendes age como masoquista ao permitir ...</td>\n",
       "      <td>gilmar mendes age masoquista permitir miller f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>fake</td>\n",
       "      <td>11</td>\n",
       "      <td>fake-br-corpus-sample/fake/11.txt</td>\n",
       "      <td>Garotinho ganha prêmio após teatro sobre surr...</td>\n",
       "      <td>garotinho ganha premio apos teatro sobre vai p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>true</td>\n",
       "      <td>18</td>\n",
       "      <td>fake-br-corpus-sample/true/18.txt</td>\n",
       "      <td>Fachin nega novo pedido de liberdade de Joesle...</td>\n",
       "      <td>fachin nega novo pedido liberdade joesley bati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fake</td>\n",
       "      <td>8</td>\n",
       "      <td>fake-br-corpus-sample/fake/8.txt</td>\n",
       "      <td>Hoje completou um ano da morte de um dos psico...</td>\n",
       "      <td>hoje completou ano morte psicopatas repulsivos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>true</td>\n",
       "      <td>9</td>\n",
       "      <td>fake-br-corpus-sample/true/9.txt</td>\n",
       "      <td>s doleiros acusados de lavar dinheiro roubado ...</td>\n",
       "      <td>s doleiros acusados lavar dinheiro roubado qua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CATEGORY NAME                               PATH  \\\n",
       "19     true   11  fake-br-corpus-sample/true/11.txt   \n",
       "16     true   17  fake-br-corpus-sample/true/17.txt   \n",
       "15     true   10  fake-br-corpus-sample/true/10.txt   \n",
       "26     fake   18  fake-br-corpus-sample/fake/18.txt   \n",
       "4      true   16  fake-br-corpus-sample/true/16.txt   \n",
       "12     true    4   fake-br-corpus-sample/true/4.txt   \n",
       "37     fake   19  fake-br-corpus-sample/fake/19.txt   \n",
       "27     fake   13  fake-br-corpus-sample/fake/13.txt   \n",
       "39     fake   11  fake-br-corpus-sample/fake/11.txt   \n",
       "6      true   18  fake-br-corpus-sample/true/18.txt   \n",
       "25     fake    8   fake-br-corpus-sample/fake/8.txt   \n",
       "9      true    9   fake-br-corpus-sample/true/9.txt   \n",
       "\n",
       "                                              CONTENT  \\\n",
       "19  Anthony Garotinho é ouvido mais uma vez sobre ...   \n",
       "16  ﻿Juiz determina soltura de 4 presos por pensão...   \n",
       "15  Bolsonaro é um liberal completo, diz president...   \n",
       "26  Joesley chorou ao entrar na cela e está sem co...   \n",
       "4   Conselho de Ética do PMDB decide expulsar a se...   \n",
       "12  ﻿Doria vai receber Zé Celso após reunião com r...   \n",
       "37  Nós vamos estuprar os corruptos afirmam pres...   \n",
       "27  Gilmar Mendes age como masoquista ao permitir ...   \n",
       "39  Garotinho ganha prêmio após teatro sobre surr...   \n",
       "6   Fachin nega novo pedido de liberdade de Joesle...   \n",
       "25  Hoje completou um ano da morte de um dos psico...   \n",
       "9   s doleiros acusados de lavar dinheiro roubado ...   \n",
       "\n",
       "                                  CONTENT_NORMALIZADO  \n",
       "19  anthony garotinho ouvido vez sobre suposta agr...  \n",
       "16  determina soltura presos pensao alimenticia co...  \n",
       "15  bolsonaro liberal completo diz presidente psl ...  \n",
       "26  joesley chorou entrar cela comer tomar banho d...  \n",
       "4   conselho etica pmdb decide expulsar senadora k...  \n",
       "12  vai receber ze celso apos reuniao representant...  \n",
       "37  vamos estuprar afirmam presos papuda mensagens...  \n",
       "27  gilmar mendes age masoquista permitir miller f...  \n",
       "39  garotinho ganha premio apos teatro sobre vai p...  \n",
       "6   fachin nega novo pedido liberdade joesley bati...  \n",
       "25  hoje completou ano morte psicopatas repulsivos...  \n",
       "9   s doleiros acusados lavar dinheiro roubado qua...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide dados em treinamento e teste\n",
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5487a556",
   "metadata": {},
   "source": [
    "## Contrução do modelo de bag of words para os dados de treinamento e submissão do modelo ao Naive Bayes\n",
    "Para que o algoritmo de classificação consiga interpretar os documentos, precisamos construir a matriz de documentos X palavras (modelo bag of words). Foi criado um Pipeline para deixar concisa a sequência de passos para preparar os textos para submeter ao Naive Bayes. Inicialmente, foi criado um feature vector contendo a quantidade de vezes que cada palavra aparece no documento. Na sequência, o dicionário de palavras gerado no passo anterior foi submetido ao TF-IDF, para que o peso das palavras seja ajustado de acordo com a importância (rartidade) do termo e sua frequência no documento. Por fim, o dicionário é submetido ao Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0093a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "data_train = df_train['CONTENT_NORMALIZADO']\n",
    "target_train = df_train['CATEGORY']\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),])\n",
    "text_clf = text_clf.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ed8a0",
   "metadata": {},
   "source": [
    "## Classificação dos documentos de teste\n",
    "Usando o mesmo algoritmo treinado, fazemos a classificação dos documentos separados para testes (com a categoria removida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5327fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = df_test['CONTENT_NORMALIZADO']\n",
    "target_test = df_test['CATEGORY']\n",
    "\n",
    "predicted = text_clf.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debded21",
   "metadata": {},
   "source": [
    "Abaixo mostramos as métricas de precision, recall e f-score dos resultados. Como se pode ver, o classificador não apresentou um bom desempenho. Isso era esperado, considerando que este é um dataset muito pequeno para uma boa classificação (exercício: replique os testes no dataset completo). Na sequência exibimos os dados classificados para se inspecionar os erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef598b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4857142857142857, 0.4857142857142857, 0.48571428571428577, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision_recall_fscore_support(target_test, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559ec091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>anthony garotinho ouvido vez sobre suposta agr...</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>determina soltura presos pensao alimenticia co...</td>\n",
       "      <td>fake</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bolsonaro liberal completo diz presidente psl ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>joesley chorou entrar cela comer tomar banho d...</td>\n",
       "      <td>true</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conselho etica pmdb decide expulsar senadora k...</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vai receber ze celso apos reuniao representant...</td>\n",
       "      <td>fake</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>vamos estuprar afirmam presos papuda mensagens...</td>\n",
       "      <td>true</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gilmar mendes age masoquista permitir miller f...</td>\n",
       "      <td>true</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>garotinho ganha premio apos teatro sobre vai p...</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fachin nega novo pedido liberdade joesley bati...</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hoje completou ano morte psicopatas repulsivos...</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s doleiros acusados lavar dinheiro roubado qua...</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Content Predicted  True\n",
       "19  anthony garotinho ouvido vez sobre suposta agr...      true  true\n",
       "16  determina soltura presos pensao alimenticia co...      fake  true\n",
       "15  bolsonaro liberal completo diz presidente psl ...      fake  true\n",
       "26  joesley chorou entrar cela comer tomar banho d...      true  fake\n",
       "4   conselho etica pmdb decide expulsar senadora k...      true  true\n",
       "12  vai receber ze celso apos reuniao representant...      fake  true\n",
       "37  vamos estuprar afirmam presos papuda mensagens...      true  fake\n",
       "27  gilmar mendes age masoquista permitir miller f...      true  fake\n",
       "39  garotinho ganha premio apos teatro sobre vai p...      fake  fake\n",
       "6   fachin nega novo pedido liberdade joesley bati...      true  true\n",
       "25  hoje completou ano morte psicopatas repulsivos...      fake  fake\n",
       "9   s doleiros acusados lavar dinheiro roubado qua...      true  true"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Content': df_test['CONTENT_NORMALIZADO'], 'Predicted': predicted, 'True': target_test})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pln]",
   "language": "python",
   "name": "conda-env-pln-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
